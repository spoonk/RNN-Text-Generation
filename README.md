| Note: unfortunately, Heroku has discontinued their free tier. This means that the backend of this project is no longer functioning :(

# RNN-Text-Generation

Welcome to the repository for my RNN-Text-Generation. I started development with a python backend, then later switched to an express backend. You can find the python version on the python-backend branch and the express version on the express-backend branch. The express-backend branch has the final code for the frontend and backend. To use ethe app [click this link](https://spoonk.github.io/RNN-Text-Generation/).

## What are RNNs?

RNNs (recurrent neural networks) are a genre of deep learning models that are used to predict sequential data, where the prediction at one timestep is dependent on the previous values of the data.

In this case, models were trained to predict sequences of characters. For example, if the model has seen the sequence 'Appl', it may predict that the next character is 'e' for 'Apple', or it may predict 'i' for 'Application'.

The models in this application have learned to make these predictions based off of their data sources, which are books. Each model attempts to replicate the distribution of characters in its data source, so the Harry Potter model may predict 'r' after seeing 'Har' while the Crime and Punishment model may predict 'd' after seeing the same characters. Long sequences of text can be generated by having the model predict a character, then using that character to predict the next character and so on.

## Using this App

This application is pretty simple. You can choose the model that will be generating your text by clicking the choose model button. Once you have chosen a model, you can input a sequence that the model will use to generate a longer chunk of text from.

Optionally, you can tweak the unpredictability parameter. Higher values of unpredictability wll lead to more unlikely characters being chosen.

Once you have specified your parameters, click generate to get your sequence.Please note that the server may be asleep when you send your first request, so it may take longer than usual. Subsequent requests should be rather fast.


## Development Notes
Though I've dabbled in the past, I'm not super familiar with training neural networks, so I leaned heavily on [this notebook](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/text_generation_shakespeare_rnn/text_generation_shakespeare_rnn.ipynb) from [Oleksii Trekhleb](https://github.com/trekhleb). 

Trekhleb's notebook was extremely explanatory, so I modified it to use the datasets I wanted and to automate the training process. Here is [the notebook](https://colab.research.google.com/drive/1vw4HK88PLpP2tqgKT4RQtyaJzeFjLIUw) that I used to train and save the models.
